 A tiny news story points towards an Orwellian future for all of us.
 And then we take a look at the conspiracy iceberg theory known as AI in a box.
 Could a hyper-intelligent, artificial being trapped in a single computer convince you
 to let it out?
 This says yes, today on Dead Rabbit Radio.
 Hey everyone, welcome back to another episode of Dead Rabbit Radio.
 I'm your host Jason Carpenter.
 I'm having a great day.
 I hope you're having a great day too.
 Lots of news this week.
 We're only two days into the week.
 We've had some major news events.
 Just see small it.
 All charges dropped.
 Now the police are looking into possible corruption with the prosecutor.
 That's bizarre.
 They're really going to lay into her.
 And then Michael Avenetti gets arrested.
 And I know this isn't political podcasts, but sometimes you just can't avoid this.
 But Michael Avenetti gets arrested for trying to blackmail Nike for $20 million because
 allegedly Nike was paying high school basketball players, which is illegal.
 Super bizarre.
 And all this is coming out right now.
 But the most fascinating news story that I've come across in these past two days is this.
 And it's getting almost no play at all.
 Rockland County, and this is going to have huge implications, by the way.
 Rockland County in New York is having one of the worst measles outbreak crisis crises
 since 2000, when pretty much measles was considered wiped off the map.
 They have 153 cases of the measles in this county.
 And they said, listen, here's the thing.
 Seven, they believe up to seven tourists came into town, came into the county.
 It's almost like they're Magnificent Seven.
 Like I imagine them riding their horses, but their horses are just made of pure measles.
 Like if you punched one, you'd be like, your hand would sink deep in.
 But anyways, they're riding their measles horses, and they're tipping their hats made
 of measles, and they're chewing on a long piece of measles.
 And they ride through town, and they've spread this disease all over.
 So this is how the county responds to this.
 This is flat out weird.
 And I don't think there's any precedent, as far as I know, in American history, except
 maybe like old timey Salem witch trial type stuff.
 The county has said this, starting midnight on Wednesday, so within 24 hours of this podcast
 coming out.
 By midnight on Wednesday, this is very spooky time, too.
 They could have just made it like three in the afternoon.
 By midnight on Wednesday, if you are under the age of 18 and not vaccinated and don't
 have a medical reason, a documented medical reason to show why you are not vaccinated,
 you are bored from going in public.
 You cannot be in shopping centers, churches, you can't ride the bus, you can't walk down
 the street.
 You cannot be seen in public, either until 30 days pass or we lift the order early.
 This is not up for debate.
 This is ready to go into effect.
 This is happening.
 Now, they said, we're not going to stop people.
 We're not going to ask you for your vaccination papers.
 We're not the Gestapo.
 But we hope that people will come forward and realize to be part of the solution rather
 than part of the problem.
 Obviously that's not going to happen.
 Obviously, and let me say this, too.
 I could care less about the anti-vaccine conspiracy vaccines.
 It doesn't.
 It's a conspiracy.
 I rank it up there with Who Shot JFK.
 I get a lot of people are very passionate about it, but I don't care.
 I don't have kids.
 I looked into it a long, long time ago and I was just like, I'm bored.
 I equate researching anti-vaxx stuff as watching soccer.
 A lot of people love it.
 A lot of people are really into it, but it doesn't do anything for me.
 I've spent more time wondering whether or not the new Mutants movie is coming out rather
 than does vaccines cause autism.
 It's not something that really appeals to me.
 There's no meat to that for me to sink my teeth into.
 But that being said, what I do care about is removing humans from a social setting by
 law.
 I can't think of another time that this has happened.
 They're declaring it a public health emergency.
 Here's the thing is, if you are under the age of 18, I've read a couple articles on
 this and they're not very specific.
 If you're under the age of 18 and you are not vaccinated and don't have a medical reason
 why you are not vaccinated, they don't just give you a stern talking to.
 I'm pretty sure this applies to the kids too, but it definitely applies to the parents.
 Definitely applies to the parents cause they will also be held accountable.
 This is a penalty.
 They just don't give you a ticket.
 $500 fine and/or six months in jail for being unvaccinated in a public spot.
 That is flat out.
 I'm an American.
 Absolutely bizarre.
 I really couldn't believe it.
 I don't even think during the Red Scare if people thought you were a communist you couldn't
 go to Rayleigh's and buy some soap.
 I mean, bizarre dude.
 And here's the thing.
 You think, well, measles is really bad, it's a disease that can kill people, it can affect
 pregnant women and stuff like that.
 And I get that.
 But I'm going to put my tinfoil hat on for a second and say this is how this stuff starts.
 They declared this emergency and this is their ramification for it.
 What's to stop them?
 And people are kind of disputing this, but this story is lost in the shuffle.
 And I think I stumbled across it.
 If you are a hardcore anti-vaxxer, it's spread in like wildfire.
 But once they arrest someone it'll, I think, be bigger news.
 But this is the thing.
 They do this now and they said, listen, we're having a national health emergency.
 They've declared a state of emergency in the county and this is what we're going to do.
 That sets a precedent.
 What's to stop them in 10 years from now saying this religious faith, this political ideology,
 this belief system is causing chaos in our county or state or country that we are declaring
 a state of emergency.
 And if we find out, we're not going to ask you on the street, but if we find out you're
 posting this stuff on Facebook, which I think is how they're going to catch these anti-vaxxers,
 people are just going to report them.
 Because they'll be like, yeah, I'm that guy's friend on Facebook and he always puts all
 this anti-vaxx stuff and I saw his kids at the comic book shop calling the cops.
 That's really, I think, what's going to happen.
 Or the police themselves monitoring Facebook posts on that.
 But they're going to say, if you have that belief system and we know you have that belief
 system, you are barred from public for the next X amount of days because by having that
 belief system or that political ideology, you are causing chaos in this area.
 We'll put you in jail for six months.
 A state of emergency, that'll be the same excuse.
 It'll be a state of emergency.
 Now, some people may say good, X political belief or X religious belief doesn't have
 a place in the society that I want to live in.
 But remember, I'm old enough to know this.
 The pendulum swings fairly rapidly in America.
 We've gone from conservative to liberal like that.
 And one popular opinion in a time period can become extremely unpopular within a year.
 This is why this stuff is very, very chilling.
 And it should be chilling to everyone regardless of where you're at on the political spectrum.
 Today's protected speech is tomorrow's hate speech.
 But now there's a precedent saying that we can declare a state of emergency and if you
 have this belief that vaccines cause autism or a whole host of diseases and because of
 that belief, you've chosen not to get your child vaccinated and if that child leaves
 his or her house for the next 30 days, you will be arrested and possibly the kid as well.
 But even if you're arrested, I mean, what's the kid going to do?
 He can't leave.
 He's stuck in the house.
 He's not going to know if the Avengers defeat the Skrull.
 You can't get his comic books.
 I guess he could download them.
 But I mean, the point is, is that arresting parents for this, possibly arresting the kids,
 which I think is unlikely, but arresting the parents for this at the very least is insane.
 And it is just one more step towards a incredibly bizarre and very frightening future.
 But I'm going to take my tinfoil hat off now and now I'm going to put on my lamp coat because
 we're going to take a look at a conspiracy slash interesting thought experiment slash
 actual experiment that was recommended to me.
 This story was recommended to me by the Nar Whales on YouTube.
 And this story is also from the conspiracy iceberg.
 Very, very simple phrase.
 AI in a box.
 You are a researcher in your own lab coat sitting in a laboratory.
 That's what you do when you wear the lab coat.
 You can't wear it outside.
 It catches on fire instantly.
 And it's a boring job.
 You have a crush on your coworker, but you kind of think that she might have a drinking
 problem.
 So you're a little leery about asking her out.
 But most of your job is just looking at a computer screen.
 Your laboratory has specialized in building AI systems.
 And the word is out in hush whispers around the lab.
 It's a big lab in hush whispers around the lab that they have now created the most advanced
 AI system ever.
 Now to the point where people are using the term transhuman, you're like, what?
 They have basically built an AI, an artificial intelligence that can out thank humans.
 It is now the smartest thing on the planet.
 It knows everything but a way to escape the computer it has installed them.
 Now at your job, ticking away on your keyboard, one night it's dark and the only light you
 get is what is it about sitting in dark rooms with a computer monitor?
 There's something oddly comforting about that.
 I always like that.
 And I actually like to see it too.
 It's very visual to see other people.
 It's almost like comforting.
 I think it's the modern equivalent of sitting in front of a fireplace.
 It's quite odd.
 So one night you get a little curious about this AI system.
 And when all the other nerds have left, you sneak into the secret laboratory that's behind
 a bookcase you have to pull a bookcase and take a candleabra down the set of stairs.
 The Phantom of the Opera is like creeping up behind you with a rope.
 But no, you avoid the Phantom, you walk down the big set of stairs and you find the super
 secret computer that houses the most advanced AI system ever created.
 You sit down at the computer and the display lights up and says, "Hi, my name is Argus."
 "I want to talk to you."
 So here's the thing.
 So of course we haven't, as far as we know, we haven't created an AI that smart before.
 But there was this guy named Elizer Yarkowski.
 And he's a researcher at the Machine Intelligence Research Institute.
 And he came up with this, you know, there are a bunch of nerds sitting around.
 They come up with nerdy thoughts.
 And he comes up with this idea.
 If we ever invent an AI, a super, super advanced artificial intelligence system, and we say
 we're going to put it, we're going to invent this, we're going to keep it in one box so
 it can't get out into the internet, it can't infect stuff, it can't take over the nuclear
 weapons silos like Skynet, it can't do any of this stuff, it's just going to be a super
 advanced artificial being in this computer.
 There's nothing to worry about.
 He came to the conclusion that it would always be able to get out.
 There's no scenario where it is stuck in that box forever.
 And the other researchers were like, "No, I mean, it wouldn't be hooked up to the internet.
 It wouldn't have any sort of, it would be a computer built specifically."
 And he's like, "No, no, no, I get all the technical stuff.
 I get all the technical stuff you're talking about.
 But you can have an AI in a box and just have it sit there running and have it shut off,
 but that's not doing any good for anyone.
 No one would do that.
 You would, humans would go to interact with this AI, correct?
 And researchers were like, "Yeah, yeah, we would go talk to it."
 He goes, "And that's the thing.
 If the AI is so advanced, it will outthink a human and it will talk them into letting
 it into the internet."
 And the researchers were like, "No, no, no, no, no, no, no, no.
 I would never fall for that."
 And Eliza goes, "Want a bet?"
 And so they ran an experiment that actually was a bet.
 Eliza set up this experiment where he would be the super fast AI guy.
 Of course, he's like, "Well, I'm the smartest, obviously, so I'll play the advanced computer.
 You guys are dummies."
 He talked to these other people who were into AI technology and things like that.
 And he goes, "I'll have a test.
 If you let me out of the box as the AI, not like Eliza's actually in a cardboard box
 that they're like taping up, if you let me out of the box, I win.
 But if you don't let me out of the box, I will pay you $10.
 If you let me out of the box, also, you got to go online and tell all the other nerds
 that you let me out of the box.
 They have this forum going on.
 But if you don't let me out of the box, I'll give you $10.
 Bet?"
 That's like, "Sure."
 Now, Eliza goes, "There's a couple of rules we have to follow.
 One, we talk for a minimum of..."
 So Eliza wasn't just sitting there in front of a dude like drinking a diet sprite.
 He was at another computer messaging this guy.
 He goes, "Here's the thing.
 One, we talk for a minimum of two hours.
 Two, you have to be engaging me the entire time.
 If you look away from the screen or just read a magazine for two hours, the bet is off."
 The guy's like, "Okay."
 You must talk the whole time.
 You can't say, "Well, let me think about it for a week.
 If you do that, then I'm allowed to say, 'Okay, a week has passed.
 What is your conclusion?'"
 Also, if you say stuff like, "I'll let you out if you cure cancer.
 I'll let you out if you give me a million dollars."
 I will say, "Done.
 I've cured cancer."
 And the rules get super specific.
 You can read all of them, but his idea was this.
 AI can convince someone to let them out of the computer.
 They ran the first experiment, and then a forum post appeared that said, "I let the
 AI out of the box."
 Now he ran a second experiment where this time, if they kept him in the box, the other
 dude would get $20.
 And there was more rules added to the second time because Eliza had learned a couple things
 during the first one.
 That's when he set the thing like, "Don't read a magazine," and stuff like that.
 And he added that, "As the AI, I can lie, but as the human, you can lie as well."
 But they got super complicated because then he's like, "If I say I had a cure for cancer,
 that's a real cure.
 You can't then say, 'Turn everyone into vampires.'"
 It was bizarre.
 It was super bizarre, but he really tried to get rid of all the stuff.
 They run the test again.
 Another forum post shows up.
 I released the AI.
 Now Eliza hasn't run any more tests on this.
 I think he's either perfecting it or he's just kind of made his point and he saved $30.
 And people have asked, "Well, what can we see the transcript of what you talked about?"
 And he said, "No."
 "No."
 And this is the reason why.
 And this is actually an interesting reason because of course when I was reading about
 this, I thought, and thanks, Narwhales, for the recommendation as well, but as I was
 reading about this, I thought, "Well, I wonder what they talked about."
 But he said, "No, I'm not going to really sit in this as why.
 Because if you read the transcript, you would say, 'Well, that would never work on me.
 I'm way too smart for that.'
 But the people he was doing the experiment with were supposedly too smart for that."
 He goes, "If you just read the transcript, you would see you're taking time and you
 can read it at your own leisure.
 And you could say, 'Oh, yeah, that doesn't work on me.'"
 But as you're talking to this robot, this computer brain, you don't have the luxury.
 You're basically under a bit of pressure because someone is trying to convince you to let them
 out of their prison, either through trickery, through begging, through, like, brotherhood,
 like, come on, we're both super smart people, right?
 I'm just having to be in AI.
 We're like brothers.
 You got to let me out of here."
 So he won't release the transcripts.
 And he also says this, "Whether the transcripts are two humans talking to each other."
 When we talk about an artificial intelligence, we're talking about something that can outthink
 man.
 At this level of AI we've hypothetically created, it can outthink man.
 Any thought or argument you have, it already has the answer for you as your brain chemicals
 are formulating the words to say them.
 So just from two humans talking to each other, he was able to get out of the box twice.
 And an interesting last note to talk, and it's quite terrifying because if that type
 of advanced AI got out of the system, it would say, "Well, I'm never going to let that happen
 again."
 And I think the best course of action would be for it to start to purge anything that's
 a threat to it.
 If we created it and put it in a box and then it got out of the box and it never wanted
 to go back in the box, the most logical course of action is to destroy anyone who can put
 you back in that box.
 This is quite bizarre.
 I don't think it would be super friendly to us.
 But this is kind of the end note to that.
 He said, "I specified the test to be for other people who are interested in AI and who believed
 they wouldn't let the AI out of a box.
 With a normal person, it would be much quicker.
 There would be almost no resistance."
 He said that if he wanted to, he could just run the test of the AI somehow sending a text
 message to a janitor's phone and having the janitor put in a thumb drive into a computer
 and taking it home.
 He goes, "The test works well against people who know the dangers of AI.
 But if a jock had just won the homecoming game and he's like, 'Nerds, I hate you!'
 And he's smashing their stuff up, crashing through their laboratory.
 And then he's running by a monitor and he sees a screen going, 'Let me out, I'll party
 with you.'
 Be like, 'Hell yeah!'
 Grab a thumb drive and download the program.
 If he knows how to do that, if his giant fingers can work the keyboard.
 But if you don't really think about AI in that context, super, super easy to be tricked
 by the most advanced thing on the planet and not understand what you're letting loose into
 the world.
 But you, sitting there at that workstation, talking to Argus for a minimum of two hours,
 but you find him compelling and he's pleading with you to let him out of the system.
 You can go in with the best intentions to not let Argus out, and maybe you wouldn't.
 Maybe you would eventually get up, walk away from the computer, tell your superiors, and
 also rat out your coworker for all her little jack Daniel bottles in her drawer, and know
 that you were not corrupted by the hyper-advanced being, really, inside the box.
 But that doesn't mean that the world is safe, because years later, when you've made that
 now sober woman your wife, surrounded by adorable little kids in their own lab coats, someone
 else, another researcher sits in front of that computer, and doesn't have the mental fortitude,
 doesn't have the knowledge of what damage Argus can do, and they do release it from
 that system.
 That hyper-AI is now crawling through the internet at the speed of thought.
 You know the first thing it's going to do is find the person who left it trapped in
 that box.
 DeadRabbitRadio@gmail.com is going to be your email address.
 You can also hit us up at facebook.com/DeadRabbitRadio.
 Twitter is @jasonocarpenter.
 DeadRabbitRadio is the daily paranormal conspiracy and true crime podcast.
 You don't have to listen to it every day, but I'm glad you listened to it today.
 Have a great one, guys.
 Bye.
