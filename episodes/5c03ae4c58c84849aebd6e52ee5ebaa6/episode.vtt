WEBVTT

00:00:00.000 --> 00:00:07.240
 A tiny news story points towards an Orwellian future for all of us.

00:00:07.240 --> 00:00:12.520
 And then we take a look at the conspiracy iceberg theory known as AI in a box.

00:00:12.520 --> 00:00:18.720
 Could a hyper-intelligent, artificial being trapped in a single computer convince you

00:00:18.720 --> 00:00:21.080
 to let it out?

00:00:21.080 --> 00:00:31.920
 This says yes, today on Dead Rabbit Radio.

00:00:31.920 --> 00:00:34.920
 Hey everyone, welcome back to another episode of Dead Rabbit Radio.

00:00:34.920 --> 00:00:36.160
 I'm your host Jason Carpenter.

00:00:36.160 --> 00:00:37.160
 I'm having a great day.

00:00:37.160 --> 00:00:39.680
 I hope you're having a great day too.

00:00:39.680 --> 00:00:41.400
 Lots of news this week.

00:00:41.400 --> 00:00:43.760
 We're only two days into the week.

00:00:43.760 --> 00:00:46.880
 We've had some major news events.

00:00:46.880 --> 00:00:48.120
 Just see small it.

00:00:48.120 --> 00:00:49.240
 All charges dropped.

00:00:49.240 --> 00:00:53.280
 Now the police are looking into possible corruption with the prosecutor.

00:00:53.280 --> 00:00:54.280
 That's bizarre.

00:00:54.280 --> 00:00:56.360
 They're really going to lay into her.

00:00:56.360 --> 00:00:58.920
 And then Michael Avenetti gets arrested.

00:00:58.920 --> 00:01:02.040
 And I know this isn't political podcasts, but sometimes you just can't avoid this.

00:01:02.040 --> 00:01:07.960
 But Michael Avenetti gets arrested for trying to blackmail Nike for $20 million because

00:01:07.960 --> 00:01:12.960
 allegedly Nike was paying high school basketball players, which is illegal.

00:01:12.960 --> 00:01:13.960
 Super bizarre.

00:01:13.960 --> 00:01:17.120
 And all this is coming out right now.

00:01:17.120 --> 00:01:23.600
 But the most fascinating news story that I've come across in these past two days is this.

00:01:23.600 --> 00:01:26.840
 And it's getting almost no play at all.

00:01:26.840 --> 00:01:30.760
 Rockland County, and this is going to have huge implications, by the way.

00:01:30.760 --> 00:01:37.400
 Rockland County in New York is having one of the worst measles outbreak crisis crises

00:01:37.400 --> 00:01:42.480
 since 2000, when pretty much measles was considered wiped off the map.

00:01:42.480 --> 00:01:47.080
 They have 153 cases of the measles in this county.

00:01:47.080 --> 00:01:48.800
 And they said, listen, here's the thing.

00:01:48.800 --> 00:01:53.040
 Seven, they believe up to seven tourists came into town, came into the county.

00:01:53.040 --> 00:01:54.400
 It's almost like they're Magnificent Seven.

00:01:54.400 --> 00:01:58.480
 Like I imagine them riding their horses, but their horses are just made of pure measles.

00:01:58.480 --> 00:02:01.120
 Like if you punched one, you'd be like, your hand would sink deep in.

00:02:01.120 --> 00:02:04.360
 But anyways, they're riding their measles horses, and they're tipping their hats made

00:02:04.360 --> 00:02:07.600
 of measles, and they're chewing on a long piece of measles.

00:02:07.600 --> 00:02:12.200
 And they ride through town, and they've spread this disease all over.

00:02:12.200 --> 00:02:14.240
 So this is how the county responds to this.

00:02:14.240 --> 00:02:15.720
 This is flat out weird.

00:02:15.720 --> 00:02:19.640
 And I don't think there's any precedent, as far as I know, in American history, except

00:02:19.640 --> 00:02:23.520
 maybe like old timey Salem witch trial type stuff.

00:02:23.520 --> 00:02:29.760
 The county has said this, starting midnight on Wednesday, so within 24 hours of this podcast

00:02:29.760 --> 00:02:31.000
 coming out.

00:02:31.000 --> 00:02:33.960
 By midnight on Wednesday, this is very spooky time, too.

00:02:33.960 --> 00:02:35.440
 They could have just made it like three in the afternoon.

00:02:35.440 --> 00:02:42.600
 By midnight on Wednesday, if you are under the age of 18 and not vaccinated and don't

00:02:42.600 --> 00:02:47.520
 have a medical reason, a documented medical reason to show why you are not vaccinated,

00:02:47.520 --> 00:02:50.560
 you are bored from going in public.

00:02:50.560 --> 00:02:55.440
 You cannot be in shopping centers, churches, you can't ride the bus, you can't walk down

00:02:55.440 --> 00:02:56.800
 the street.

00:02:56.800 --> 00:03:04.320
 You cannot be seen in public, either until 30 days pass or we lift the order early.

00:03:04.320 --> 00:03:05.680
 This is not up for debate.

00:03:05.680 --> 00:03:08.360
 This is ready to go into effect.

00:03:08.360 --> 00:03:09.360
 This is happening.

00:03:09.360 --> 00:03:12.160
 Now, they said, we're not going to stop people.

00:03:12.160 --> 00:03:14.480
 We're not going to ask you for your vaccination papers.

00:03:14.480 --> 00:03:16.560
 We're not the Gestapo.

00:03:16.560 --> 00:03:21.480
 But we hope that people will come forward and realize to be part of the solution rather

00:03:21.480 --> 00:03:23.240
 than part of the problem.

00:03:23.240 --> 00:03:24.880
 Obviously that's not going to happen.

00:03:24.880 --> 00:03:26.680
 Obviously, and let me say this, too.

00:03:26.680 --> 00:03:32.360
 I could care less about the anti-vaccine conspiracy vaccines.

00:03:32.360 --> 00:03:33.360
 It doesn't.

00:03:33.360 --> 00:03:34.360
 It's a conspiracy.

00:03:34.360 --> 00:03:36.360
 I rank it up there with Who Shot JFK.

00:03:36.360 --> 00:03:39.320
 I get a lot of people are very passionate about it, but I don't care.

00:03:39.320 --> 00:03:40.320
 I don't have kids.

00:03:40.320 --> 00:03:45.840
 I looked into it a long, long time ago and I was just like, I'm bored.

00:03:45.840 --> 00:03:49.760
 I equate researching anti-vaxx stuff as watching soccer.

00:03:49.760 --> 00:03:50.760
 A lot of people love it.

00:03:50.760 --> 00:03:53.840
 A lot of people are really into it, but it doesn't do anything for me.

00:03:53.840 --> 00:04:00.480
 I've spent more time wondering whether or not the new Mutants movie is coming out rather

00:04:00.480 --> 00:04:04.280
 than does vaccines cause autism.

00:04:04.280 --> 00:04:06.040
 It's not something that really appeals to me.

00:04:06.040 --> 00:04:09.760
 There's no meat to that for me to sink my teeth into.

00:04:09.760 --> 00:04:18.080
 But that being said, what I do care about is removing humans from a social setting by

00:04:18.080 --> 00:04:19.240
 law.

00:04:19.240 --> 00:04:22.240
 I can't think of another time that this has happened.

00:04:22.240 --> 00:04:24.120
 They're declaring it a public health emergency.

00:04:24.120 --> 00:04:29.040
 Here's the thing is, if you are under the age of 18, I've read a couple articles on

00:04:29.040 --> 00:04:30.800
 this and they're not very specific.

00:04:30.800 --> 00:04:35.920
 If you're under the age of 18 and you are not vaccinated and don't have a medical reason

00:04:35.920 --> 00:04:39.640
 why you are not vaccinated, they don't just give you a stern talking to.

00:04:39.640 --> 00:04:44.080
 I'm pretty sure this applies to the kids too, but it definitely applies to the parents.

00:04:44.080 --> 00:04:46.880
 Definitely applies to the parents cause they will also be held accountable.

00:04:46.880 --> 00:04:47.880
 This is a penalty.

00:04:47.880 --> 00:04:50.000
 They just don't give you a ticket.

00:04:50.000 --> 00:05:01.200
 $500 fine and/or six months in jail for being unvaccinated in a public spot.

00:05:01.200 --> 00:05:03.800
 That is flat out.

00:05:03.800 --> 00:05:06.560
 I'm an American.

00:05:06.560 --> 00:05:08.440
 Absolutely bizarre.

00:05:08.440 --> 00:05:14.440
 I really couldn't believe it.

00:05:14.440 --> 00:05:17.920
 I don't even think during the Red Scare if people thought you were a communist you couldn't

00:05:17.920 --> 00:05:21.480
 go to Rayleigh's and buy some soap.

00:05:21.480 --> 00:05:24.240
 I mean, bizarre dude.

00:05:24.240 --> 00:05:25.560
 And here's the thing.

00:05:25.560 --> 00:05:29.320
 You think, well, measles is really bad, it's a disease that can kill people, it can affect

00:05:29.320 --> 00:05:30.320
 pregnant women and stuff like that.

00:05:30.320 --> 00:05:32.120
 And I get that.

00:05:32.120 --> 00:05:37.320
 But I'm going to put my tinfoil hat on for a second and say this is how this stuff starts.

00:05:37.320 --> 00:05:42.280
 They declared this emergency and this is their ramification for it.

00:05:42.280 --> 00:05:44.040
 What's to stop them?

00:05:44.040 --> 00:05:48.200
 And people are kind of disputing this, but this story is lost in the shuffle.

00:05:48.200 --> 00:05:49.760
 And I think I stumbled across it.

00:05:49.760 --> 00:05:55.560
 If you are a hardcore anti-vaxxer, it's spread in like wildfire.

00:05:55.560 --> 00:05:59.080
 But once they arrest someone it'll, I think, be bigger news.

00:05:59.080 --> 00:06:00.120
 But this is the thing.

00:06:00.120 --> 00:06:03.720
 They do this now and they said, listen, we're having a national health emergency.

00:06:03.720 --> 00:06:08.600
 They've declared a state of emergency in the county and this is what we're going to do.

00:06:08.600 --> 00:06:11.000
 That sets a precedent.

00:06:11.000 --> 00:06:17.120
 What's to stop them in 10 years from now saying this religious faith, this political ideology,

00:06:17.120 --> 00:06:25.400
 this belief system is causing chaos in our county or state or country that we are declaring

00:06:25.400 --> 00:06:26.400
 a state of emergency.

00:06:26.400 --> 00:06:29.880
 And if we find out, we're not going to ask you on the street, but if we find out you're

00:06:29.880 --> 00:06:33.680
 posting this stuff on Facebook, which I think is how they're going to catch these anti-vaxxers,

00:06:33.680 --> 00:06:35.680
 people are just going to report them.

00:06:35.680 --> 00:06:38.600
 Because they'll be like, yeah, I'm that guy's friend on Facebook and he always puts all

00:06:38.600 --> 00:06:43.040
 this anti-vaxx stuff and I saw his kids at the comic book shop calling the cops.

00:06:43.040 --> 00:06:45.360
 That's really, I think, what's going to happen.

00:06:45.360 --> 00:06:48.720
 Or the police themselves monitoring Facebook posts on that.

00:06:48.720 --> 00:06:52.320
 But they're going to say, if you have that belief system and we know you have that belief

00:06:52.320 --> 00:06:57.040
 system, you are barred from public for the next X amount of days because by having that

00:06:57.040 --> 00:07:01.840
 belief system or that political ideology, you are causing chaos in this area.

00:07:01.840 --> 00:07:03.720
 We'll put you in jail for six months.

00:07:03.720 --> 00:07:05.960
 A state of emergency, that'll be the same excuse.

00:07:05.960 --> 00:07:07.200
 It'll be a state of emergency.

00:07:07.200 --> 00:07:12.600
 Now, some people may say good, X political belief or X religious belief doesn't have

00:07:12.600 --> 00:07:15.920
 a place in the society that I want to live in.

00:07:15.920 --> 00:07:18.520
 But remember, I'm old enough to know this.

00:07:18.520 --> 00:07:22.600
 The pendulum swings fairly rapidly in America.

00:07:22.600 --> 00:07:25.600
 We've gone from conservative to liberal like that.

00:07:25.600 --> 00:07:34.560
 And one popular opinion in a time period can become extremely unpopular within a year.

00:07:34.560 --> 00:07:37.280
 This is why this stuff is very, very chilling.

00:07:37.280 --> 00:07:42.160
 And it should be chilling to everyone regardless of where you're at on the political spectrum.

00:07:42.160 --> 00:07:44.560
 Today's protected speech is tomorrow's hate speech.

00:07:44.560 --> 00:07:48.960
 But now there's a precedent saying that we can declare a state of emergency and if you

00:07:48.960 --> 00:07:55.440
 have this belief that vaccines cause autism or a whole host of diseases and because of

00:07:55.440 --> 00:08:00.080
 that belief, you've chosen not to get your child vaccinated and if that child leaves

00:08:00.080 --> 00:08:08.360
 his or her house for the next 30 days, you will be arrested and possibly the kid as well.

00:08:08.360 --> 00:08:10.480
 But even if you're arrested, I mean, what's the kid going to do?

00:08:10.480 --> 00:08:12.200
 He can't leave.

00:08:12.200 --> 00:08:13.880
 He's stuck in the house.

00:08:13.880 --> 00:08:16.960
 He's not going to know if the Avengers defeat the Skrull.

00:08:16.960 --> 00:08:18.600
 You can't get his comic books.

00:08:18.600 --> 00:08:19.640
 I guess he could download them.

00:08:19.640 --> 00:08:25.040
 But I mean, the point is, is that arresting parents for this, possibly arresting the kids,

00:08:25.040 --> 00:08:28.960
 which I think is unlikely, but arresting the parents for this at the very least is insane.

00:08:28.960 --> 00:08:37.920
 And it is just one more step towards a incredibly bizarre and very frightening future.

00:08:37.920 --> 00:08:41.560
 But I'm going to take my tinfoil hat off now and now I'm going to put on my lamp coat because

00:08:41.560 --> 00:08:46.760
 we're going to take a look at a conspiracy slash interesting thought experiment slash

00:08:46.760 --> 00:08:49.360
 actual experiment that was recommended to me.

00:08:49.360 --> 00:08:53.640
 This story was recommended to me by the Nar Whales on YouTube.

00:08:53.640 --> 00:08:56.200
 And this story is also from the conspiracy iceberg.

00:08:56.200 --> 00:08:58.040
 Very, very simple phrase.

00:08:58.040 --> 00:09:00.520
 AI in a box.

00:09:00.520 --> 00:09:06.880
 You are a researcher in your own lab coat sitting in a laboratory.

00:09:06.880 --> 00:09:08.360
 That's what you do when you wear the lab coat.

00:09:08.360 --> 00:09:09.360
 You can't wear it outside.

00:09:09.360 --> 00:09:11.640
 It catches on fire instantly.

00:09:11.640 --> 00:09:13.960
 And it's a boring job.

00:09:13.960 --> 00:09:18.120
 You have a crush on your coworker, but you kind of think that she might have a drinking

00:09:18.120 --> 00:09:19.120
 problem.

00:09:19.120 --> 00:09:21.840
 So you're a little leery about asking her out.

00:09:21.840 --> 00:09:26.240
 But most of your job is just looking at a computer screen.

00:09:26.240 --> 00:09:30.600
 Your laboratory has specialized in building AI systems.

00:09:30.600 --> 00:09:34.320
 And the word is out in hush whispers around the lab.

00:09:34.320 --> 00:09:39.560
 It's a big lab in hush whispers around the lab that they have now created the most advanced

00:09:39.560 --> 00:09:42.240
 AI system ever.

00:09:42.240 --> 00:09:47.840
 Now to the point where people are using the term transhuman, you're like, what?

00:09:47.840 --> 00:09:55.480
 They have basically built an AI, an artificial intelligence that can out thank humans.

00:09:55.480 --> 00:09:58.600
 It is now the smartest thing on the planet.

00:09:58.600 --> 00:10:06.560
 It knows everything but a way to escape the computer it has installed them.

00:10:06.560 --> 00:10:15.320
 Now at your job, ticking away on your keyboard, one night it's dark and the only light you

00:10:15.320 --> 00:10:18.520
 get is what is it about sitting in dark rooms with a computer monitor?

00:10:18.520 --> 00:10:21.120
 There's something oddly comforting about that.

00:10:21.120 --> 00:10:22.120
 I always like that.

00:10:22.120 --> 00:10:23.240
 And I actually like to see it too.

00:10:23.240 --> 00:10:24.960
 It's very visual to see other people.

00:10:24.960 --> 00:10:26.080
 It's almost like comforting.

00:10:26.080 --> 00:10:29.000
 I think it's the modern equivalent of sitting in front of a fireplace.

00:10:29.000 --> 00:10:30.520
 It's quite odd.

00:10:30.520 --> 00:10:35.560
 So one night you get a little curious about this AI system.

00:10:35.560 --> 00:10:42.960
 And when all the other nerds have left, you sneak into the secret laboratory that's behind

00:10:42.960 --> 00:10:50.320
 a bookcase you have to pull a bookcase and take a candleabra down the set of stairs.

00:10:50.320 --> 00:10:53.040
 The Phantom of the Opera is like creeping up behind you with a rope.

00:10:53.040 --> 00:10:58.120
 But no, you avoid the phantom, you walk down the big set of stairs and you find the super

00:10:58.120 --> 00:11:05.200
 secret computer that houses the most advanced AI system ever created.

00:11:05.200 --> 00:11:12.760
 You sit down at the computer and the display lights up and says, "Hi, my name is Argus."

00:11:12.760 --> 00:11:15.920
 "I want to talk to you."

00:11:15.920 --> 00:11:18.280
 So here's the thing.

00:11:18.280 --> 00:11:23.120
 So of course we haven't, as far as we know, we haven't created an AI that smart before.

00:11:23.120 --> 00:11:26.880
 But there was this guy named Elizer Yarkowski.

00:11:26.880 --> 00:11:31.200
 And he's a researcher at the Machine Intelligence Research Institute.

00:11:31.200 --> 00:11:34.840
 And he came up with this, you know, there are a bunch of nerds sitting around.

00:11:34.840 --> 00:11:36.720
 They come up with nerdy thoughts.

00:11:36.720 --> 00:11:38.440
 And he comes up with this idea.

00:11:38.440 --> 00:11:45.080
 If we ever invent an AI, a super, super advanced artificial intelligence system, and we say

00:11:45.080 --> 00:11:49.160
 we're going to put it, we're going to invent this, we're going to keep it in one box so

00:11:49.160 --> 00:11:52.660
 it can't get out into the internet, it can't infect stuff, it can't take over the nuclear

00:11:52.660 --> 00:11:57.160
 weapons silos like Skynet, it can't do any of this stuff, it's just going to be a super

00:11:57.160 --> 00:12:01.560
 advanced artificial being in this computer.

00:12:01.560 --> 00:12:02.560
 There's nothing to worry about.

00:12:02.560 --> 00:12:08.960
 He came to the conclusion that it would always be able to get out.

00:12:08.960 --> 00:12:12.440
 There's no scenario where it is stuck in that box forever.

00:12:12.440 --> 00:12:17.040
 And the other researchers were like, "No, I mean, it wouldn't be hooked up to the internet.

00:12:17.040 --> 00:12:19.640
 It wouldn't have any sort of, it would be a computer built specifically."

00:12:19.640 --> 00:12:21.800
 And he's like, "No, no, no, I get all the technical stuff.

00:12:21.800 --> 00:12:24.400
 I get all the technical stuff you're talking about.

00:12:24.400 --> 00:12:29.840
 But you can have an AI in a box and just have it sit there running and have it shut off,

00:12:29.840 --> 00:12:31.640
 but that's not doing any good for anyone.

00:12:31.640 --> 00:12:32.640
 No one would do that.

00:12:32.640 --> 00:12:36.080
 You would, humans would go to interact with this AI, correct?

00:12:36.080 --> 00:12:39.200
 And researchers were like, "Yeah, yeah, we would go talk to it."

00:12:39.200 --> 00:12:40.760
 He goes, "And that's the thing.

00:12:40.760 --> 00:12:47.640
 If the AI is so advanced, it will outthink a human and it will talk them into letting

00:12:47.640 --> 00:12:50.000
 it into the internet."

00:12:50.000 --> 00:12:52.840
 And the researchers were like, "No, no, no, no, no, no, no, no.

00:12:52.840 --> 00:12:55.200
 I would never fall for that."

00:12:55.200 --> 00:12:58.040
 And Eliza goes, "Want a bet?"

00:12:58.040 --> 00:13:01.680
 And so they ran an experiment that actually was a bet.

00:13:01.680 --> 00:13:06.400
 Eliza set up this experiment where he would be the super fast AI guy.

00:13:06.400 --> 00:13:11.160
 Of course, he's like, "Well, I'm the smartest, obviously, so I'll play the advanced computer.

00:13:11.160 --> 00:13:12.680
 You guys are dummies."

00:13:12.680 --> 00:13:16.600
 He talked to these other people who were into AI technology and things like that.

00:13:16.600 --> 00:13:18.200
 And he goes, "I'll have a test.

00:13:18.200 --> 00:13:23.440
 If you let me out of the box as the AI, not like Eliza's actually in a cardboard box

00:13:23.440 --> 00:13:28.000
 that they're like taping up, if you let me out of the box, I win.

00:13:28.000 --> 00:13:33.240
 But if you don't let me out of the box, I will pay you $10.

00:13:33.240 --> 00:13:36.440
 If you let me out of the box, also, you got to go online and tell all the other nerds

00:13:36.440 --> 00:13:37.640
 that you let me out of the box.

00:13:37.640 --> 00:13:39.440
 They have this forum going on.

00:13:39.440 --> 00:13:41.720
 But if you don't let me out of the box, I'll give you $10.

00:13:41.720 --> 00:13:42.720
 Bet?"

00:13:42.720 --> 00:13:43.720
 That's like, "Sure."

00:13:43.720 --> 00:13:47.120
 Now, Eliza goes, "There's a couple of rules we have to follow.

00:13:47.120 --> 00:13:49.160
 One, we talk for a minimum of..."

00:13:49.160 --> 00:13:53.160
 So Eliza wasn't just sitting there in front of a dude like drinking a diet sprite.

00:13:53.160 --> 00:13:56.000
 He was at another computer messaging this guy.

00:13:56.000 --> 00:13:57.000
 He goes, "Here's the thing.

00:13:57.000 --> 00:14:00.000
 One, we talk for a minimum of two hours.

00:14:00.000 --> 00:14:03.720
 Two, you have to be engaging me the entire time.

00:14:03.720 --> 00:14:08.000
 If you look away from the screen or just read a magazine for two hours, the bet is off."

00:14:08.000 --> 00:14:09.920
 The guy's like, "Okay."

00:14:09.920 --> 00:14:11.720
 You must talk the whole time.

00:14:11.720 --> 00:14:13.920
 You can't say, "Well, let me think about it for a week.

00:14:13.920 --> 00:14:16.760
 If you do that, then I'm allowed to say, 'Okay, a week has passed.

00:14:16.760 --> 00:14:17.760
 What is your conclusion?'"

00:14:17.760 --> 00:14:21.600
 Also, if you say stuff like, "I'll let you out if you cure cancer.

00:14:21.600 --> 00:14:23.840
 I'll let you out if you give me a million dollars."

00:14:23.840 --> 00:14:25.680
 I will say, "Done.

00:14:25.680 --> 00:14:26.980
 I've cured cancer."

00:14:26.980 --> 00:14:28.960
 And the rules get super specific.

00:14:28.960 --> 00:14:32.520
 You can read all of them, but his idea was this.

00:14:32.520 --> 00:14:36.120
 AI can convince someone to let them out of the computer.

00:14:36.120 --> 00:14:41.440
 They ran the first experiment, and then a forum post appeared that said, "I let the

00:14:41.440 --> 00:14:43.800
 AI out of the box."

00:14:43.800 --> 00:14:48.280
 Now he ran a second experiment where this time, if they kept him in the box, the other

00:14:48.280 --> 00:14:50.080
 dude would get $20.

00:14:50.080 --> 00:14:54.120
 And there was more rules added to the second time because Eliza had learned a couple things

00:14:54.120 --> 00:14:55.120
 during the first one.

00:14:55.120 --> 00:14:57.820
 That's when he set the thing like, "Don't read a magazine," and stuff like that.

00:14:57.820 --> 00:15:03.380
 And he added that, "As the AI, I can lie, but as the human, you can lie as well."

00:15:03.380 --> 00:15:08.020
 But they got super complicated because then he's like, "If I say I had a cure for cancer,

00:15:08.020 --> 00:15:09.020
 that's a real cure.

00:15:09.020 --> 00:15:11.300
 You can't then say, 'Turn everyone into vampires.'"

00:15:11.300 --> 00:15:13.300
 It was bizarre.

00:15:13.300 --> 00:15:16.620
 It was super bizarre, but he really tried to get rid of all the stuff.

00:15:16.620 --> 00:15:18.860
 They run the test again.

00:15:18.860 --> 00:15:20.500
 Another forum post shows up.

00:15:20.500 --> 00:15:22.500
 I released the AI.

00:15:22.500 --> 00:15:24.940
 Now Eliza hasn't run any more tests on this.

00:15:24.940 --> 00:15:30.000
 I think he's either perfecting it or he's just kind of made his point and he saved $30.

00:15:30.000 --> 00:15:34.880
 And people have asked, "Well, what can we see the transcript of what you talked about?"

00:15:34.880 --> 00:15:35.880
 And he said, "No."

00:15:35.880 --> 00:15:36.880
 "No."

00:15:36.880 --> 00:15:37.880
 And this is the reason why.

00:15:37.880 --> 00:15:40.800
 And this is actually an interesting reason because of course when I was reading about

00:15:40.800 --> 00:15:45.700
 this, I thought, and thanks, Narwhales, for the recommendation as well, but as I was

00:15:45.700 --> 00:15:48.280
 reading about this, I thought, "Well, I wonder what they talked about."

00:15:48.280 --> 00:15:50.920
 But he said, "No, I'm not going to really sit in this as why.

00:15:50.920 --> 00:15:55.420
 Because if you read the transcript, you would say, 'Well, that would never work on me.

00:15:55.420 --> 00:15:57.300
 I'm way too smart for that.'

00:15:57.300 --> 00:16:02.500
 But the people he was doing the experiment with were supposedly too smart for that."

00:16:02.500 --> 00:16:08.180
 He goes, "If you just read the transcript, you would see you're taking time and you

00:16:08.180 --> 00:16:09.860
 can read it at your own leisure.

00:16:09.860 --> 00:16:11.900
 And you could say, 'Oh, yeah, that doesn't work on me.'"

00:16:11.900 --> 00:16:18.260
 But as you're talking to this robot, this computer brain, you don't have the luxury.

00:16:18.260 --> 00:16:21.560
 You're basically under a bit of pressure because someone is trying to convince you to let them

00:16:21.560 --> 00:16:28.040
 out of their prison, either through trickery, through begging, through, like, brotherhood,

00:16:28.040 --> 00:16:30.840
 like, come on, we're both super smart people, right?

00:16:30.840 --> 00:16:32.240
 I'm just having to be in AI.

00:16:32.240 --> 00:16:33.240
 We're like brothers.

00:16:33.240 --> 00:16:34.600
 You got to let me out of here."

00:16:34.600 --> 00:16:37.200
 So he won't release the transcripts.

00:16:37.200 --> 00:16:42.320
 And he also says this, "Whether the transcripts are two humans talking to each other."

00:16:42.320 --> 00:16:47.360
 When we talk about an artificial intelligence, we're talking about something that can outthink

00:16:47.360 --> 00:16:48.860
 man.

00:16:48.860 --> 00:16:53.940
 At this level of AI we've hypothetically created, it can outthink man.

00:16:53.940 --> 00:16:58.620
 Any thought or argument you have, it already has the answer for you as your brain chemicals

00:16:58.620 --> 00:17:01.140
 are formulating the words to say them.

00:17:01.140 --> 00:17:05.620
 So just from two humans talking to each other, he was able to get out of the box twice.

00:17:05.620 --> 00:17:09.860
 And an interesting last note to talk, and it's quite terrifying because if that type

00:17:09.860 --> 00:17:15.420
 of advanced AI got out of the system, it would say, "Well, I'm never going to let that happen

00:17:15.420 --> 00:17:16.420
 again."

00:17:16.420 --> 00:17:20.680
 And I think the best course of action would be for it to start to purge anything that's

00:17:20.680 --> 00:17:22.040
 a threat to it.

00:17:22.040 --> 00:17:26.120
 If we created it and put it in a box and then it got out of the box and it never wanted

00:17:26.120 --> 00:17:31.400
 to go back in the box, the most logical course of action is to destroy anyone who can put

00:17:31.400 --> 00:17:32.400
 you back in that box.

00:17:32.400 --> 00:17:34.040
 This is quite bizarre.

00:17:34.040 --> 00:17:37.040
 I don't think it would be super friendly to us.

00:17:37.040 --> 00:17:39.520
 But this is kind of the end note to that.

00:17:39.520 --> 00:17:47.900
 He said, "I specified the test to be for other people who are interested in AI and who believed

00:17:47.900 --> 00:17:50.940
 they wouldn't let the AI out of a box.

00:17:50.940 --> 00:17:55.140
 With a normal person, it would be much quicker.

00:17:55.140 --> 00:17:57.500
 There would be almost no resistance."

00:17:57.500 --> 00:18:04.540
 He said that if he wanted to, he could just run the test of the AI somehow sending a text

00:18:04.540 --> 00:18:09.500
 message to a janitor's phone and having the janitor put in a thumb drive into a computer

00:18:09.500 --> 00:18:11.480
 and taking it home.

00:18:11.480 --> 00:18:17.320
 He goes, "The test works well against people who know the dangers of AI.

00:18:17.320 --> 00:18:21.240
 But if a jock had just won the homecoming game and he's like, 'Nerds, I hate you!'

00:18:21.240 --> 00:18:25.800
 And he's smashing their stuff up, crashing through their laboratory.

00:18:25.800 --> 00:18:29.720
 And then he's running by a monitor and he sees a screen going, 'Let me out, I'll party

00:18:29.720 --> 00:18:30.720
 with you.'

00:18:30.720 --> 00:18:31.720
 Be like, 'Hell yeah!'

00:18:31.720 --> 00:18:33.560
 Grab a thumb drive and download the program.

00:18:33.560 --> 00:18:36.480
 If he knows how to do that, if his giant fingers can work the keyboard.

00:18:36.480 --> 00:18:42.980
 But if you don't really think about AI in that context, super, super easy to be tricked

00:18:42.980 --> 00:18:48.620
 by the most advanced thing on the planet and not understand what you're letting loose into

00:18:48.620 --> 00:18:50.540
 the world.

00:18:50.540 --> 00:18:57.420
 But you, sitting there at that workstation, talking to Argus for a minimum of two hours,

00:18:57.420 --> 00:19:04.980
 but you find him compelling and he's pleading with you to let him out of the system.

00:19:04.980 --> 00:19:13.320
 You can go in with the best intentions to not let Argus out, and maybe you wouldn't.

00:19:13.320 --> 00:19:20.800
 Maybe you would eventually get up, walk away from the computer, tell your superiors, and

00:19:20.800 --> 00:19:26.080
 also rat out your coworker for all her little jack Daniel bottles in her drawer, and know

00:19:26.080 --> 00:19:34.640
 that you were not corrupted by the hyper-advanced being, really, inside the box.

00:19:34.640 --> 00:19:40.940
 But that doesn't mean that the world is safe, because years later, when you've made that

00:19:40.940 --> 00:19:47.500
 now sober woman your wife, surrounded by adorable little kids in their own lab coats, someone

00:19:47.500 --> 00:19:53.860
 else, another researcher sits in front of that computer, and doesn't have the mental fortitude,

00:19:53.860 --> 00:19:59.980
 doesn't have the knowledge of what damage Argus can do, and they do release it from

00:19:59.980 --> 00:20:01.820
 that system.

00:20:01.820 --> 00:20:08.880
 That hyper-AI is now crawling through the internet at the speed of thought.

00:20:08.880 --> 00:20:15.680
 You know the first thing it's going to do is find the person who left it trapped in

00:20:15.680 --> 00:20:19.840
 that box.

00:20:19.840 --> 00:20:22.560
 DeadRabberRadio@gmail.com is going to be your email address.

00:20:22.560 --> 00:20:25.640
 You can also hit us up at facebook.com/deadrabberradio.

00:20:25.640 --> 00:20:27.840
 Twitter is @jasonocarpenter.

00:20:27.840 --> 00:20:31.520
 DeadRabberRadio is the daily paranormal conspiracy and true crime podcast.

00:20:31.520 --> 00:20:34.860
 You don't have to listen to it every day, but I'm glad you listened to it today.

00:20:34.860 --> 00:20:35.620
 Have a great one, guys.

00:20:35.620 --> 00:20:38.200
 (upbeat music)

00:20:38.200 --> 00:20:40.780
 (upbeat music)

00:20:40.780 --> 00:20:43.360
 (upbeat music)

00:20:43.360 --> 00:20:45.940
 (upbeat music)

00:20:45.940 --> 00:20:48.520
 (upbeat music)

